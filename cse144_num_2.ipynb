{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab947a-653e-4ef0-b77d-e6aa723d00ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms\n",
    "import timm \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324c59a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c82e1-e626-43cd-a7e8-57f72f3c218e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57040f60-0a14-430c-bbdc-6fa982d2cb81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsorted folder names: ['38', '59', '85', '35', '5', '58', '46', '3', '71', '10', '54', '48', '17', '84', '41', '75', '88', '1', '22', '81', '52', '93', '8', '83', '37', '9', '0', '43', '51', '94', '55', '32', '19', '89', '53', '78', '63', '74', '29', '33', '70', '72', '45', '49', '15', '64', '66', '95', '23', '4', '14', '97', '65', '77', '50', '61', '62', '21', '80', '47', '24', '96', '60', '30', '57', '13', '42', '82', '87', '92', '79', '68', '12', '27', '18', '31', '11', '34', '26', '98', '25', '39', '2', '16', '6', '86', '76', '44', '56', '7', '69', '73', '28', '91', '90', '40', '67', '36', '99', '20']\n",
      "Sorted folder names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "#train_dir = \"/ucsc-cse-144-winter-2025-final-project/train/train\"\n",
    "train_dir = \"ucsc-cse-144-winter-2025-final-project/train/train\"\n",
    "folder_names = os.listdir(train_dir)\n",
    "print(\"Unsorted folder names:\", folder_names)\n",
    "\n",
    "sorted_folder_names = sorted(folder_names, key=lambda x: int(x))\n",
    "print(\"Sorted folder names:\", sorted_folder_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9afe5-6e9a-464a-b336-427b59c80871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "    \n",
    "    def find_classes(self, directory):\n",
    "        classes = sorted(os.listdir(directory))\n",
    "        classes = [cls for cls in classes if cls.isdigit()]\n",
    "        class_to_idx = {cls_name: int(cls_name) for cls_name in classes}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21d7a9-e485-4239-abc6-dfc4c3d59e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.RandomCrop(512),\n",
    "    transforms.RandomHorizontalFlip(p=0.4),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=7),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.5, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dir = \"ucsc-cse-144-winter-2025-final-project/train/train\"\n",
    "\n",
    "train_dataset = CustomImageFolder(root=train_dir, transform=train_transforms)\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "val_subset.dataset.transform = val_transforms\n",
    "\n",
    "bs = 32\n",
    "train_loader = DataLoader(train_subset, batch_size=bs, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_subset, batch_size=bs, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5b9da4-7e09-4f57-bf01-21aca1eb6625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unfreeze_layers(model, epoch, freeze_after_epoch = 5):\n",
    "    if epoch >= freeze_after_epoch:\n",
    "        for i, block in enumerate(model.blocks):\n",
    "            if i <= epoch - freeze_after_epoch:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "        print(f\"Epoch {epoch + 1}: Unfreezing block {epoch - freeze_after_epoch + 1}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991d584-4e14-47d1-a472-8f66a019b91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 100\n",
    "\n",
    "weights = ViT_L_16_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "model = vit_l_16(weights=weights)\n",
    "\n",
    "model.heads[-1] = nn.Linear(model.heads[-1].in_features, num_classes)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.heads.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80fb76e5-21f7-4336-a590-74f5c7070a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "\n",
    "# Reduced learning rate based on validation accuracy\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max= 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e9f8a-01b2-4764-be51-af379c844063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for imgs, lbls in train_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, lbls)\n",
    "\n",
    "        # Backpropagate loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == lbls).sum().item()\n",
    "        total += lbls.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total * 100\n",
    "    print(f\"Train Epoch {epoch+1}: Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb2f46b-be97-45c8-b8ab-2b2cc0e0c051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, lbls)\n",
    "\n",
    "            # Track statistics\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == lbls).sum().item()\n",
    "            total += lbls.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = correct / total * 100\n",
    "    print(f\"Validation Epoch {epoch+1}: Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55abd731-b9dc-4bef-92d6-f449a939c2bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=10):\n",
    "    scaler = GradScaler(enabled=(device.type == 'cuda'))\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # No unfreezing; backbone remains frozen.\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, epoch)\n",
    "        val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, device, epoch)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_vit_model.pth\")\n",
    "            print(f\"Model saved with accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68627d4-0557-4cb2-9602-1c2a5cf1ea39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.load_state_dict(torch.load(\"best_vit_model.pth\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in test_loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == lbls).sum().item()\n",
    "            total += lbls.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fadd1abf-47f3-474c-9957-867da9d4c930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_20674/3256764539.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(device.type == 'cuda'))\n",
      "/var/tmp/ipykernel_20674/704434108.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: Loss: 3.4641, Accuracy: 40.50%\n",
      "Validation Epoch 1: Loss: 1.7485, Accuracy: 57.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with accuracy: 57.50%\n",
      "Train Epoch 2: Loss: 0.7472, Accuracy: 79.75%\n",
      "Validation Epoch 2: Loss: 1.3202, Accuracy: 64.50%\n",
      "Model saved with accuracy: 64.50%\n",
      "Train Epoch 3: Loss: 0.3116, Accuracy: 90.38%\n",
      "Validation Epoch 3: Loss: 1.0068, Accuracy: 69.50%\n",
      "Model saved with accuracy: 69.50%\n",
      "Train Epoch 4: Loss: 0.2822, Accuracy: 93.25%\n",
      "Validation Epoch 4: Loss: 1.0348, Accuracy: 69.00%\n",
      "Train Epoch 5: Loss: 0.1864, Accuracy: 94.75%\n",
      "Validation Epoch 5: Loss: 1.0077, Accuracy: 72.50%\n",
      "Model saved with accuracy: 72.50%\n",
      "Train Epoch 6: Loss: 0.1916, Accuracy: 94.12%\n",
      "Validation Epoch 6: Loss: 1.2756, Accuracy: 69.50%\n",
      "Train Epoch 7: Loss: 0.1620, Accuracy: 95.38%\n",
      "Validation Epoch 7: Loss: 1.1525, Accuracy: 76.50%\n",
      "Model saved with accuracy: 76.50%\n",
      "Train Epoch 8: Loss: 0.0996, Accuracy: 97.38%\n",
      "Validation Epoch 8: Loss: 0.8572, Accuracy: 80.50%\n",
      "Model saved with accuracy: 80.50%\n",
      "Train Epoch 9: Loss: 0.0535, Accuracy: 99.12%\n",
      "Validation Epoch 9: Loss: 0.9339, Accuracy: 74.50%\n",
      "Train Epoch 10: Loss: 0.0619, Accuracy: 98.62%\n",
      "Validation Epoch 10: Loss: 0.9067, Accuracy: 75.50%\n",
      "Test Accuracy: 80.50%\n"
     ]
    }
   ],
   "source": [
    "numepochs = 10\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs=numepochs)\n",
    "\n",
    "evaluate_model(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32992819-f301-40a0-a80b-46d39948c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Accuracy at 80% and Kaggle accuracy at 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e743271-62c8-4d55-8b18-b026494a6447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 'submission_test4.csv' generated.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def natural_sort_key(f):\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', f)]\n",
    "\n",
    "direct_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "test_dir = \"ucsc-cse-144-winter-2025-final-project/test/test\"\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.jpg')],\n",
    "                    key=natural_sort_key)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def generate_predictions(test_dir, test_files, model, device, transform):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for file in test_files:\n",
    "            img_path = os.path.join(test_dir, file)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            # Apply transformation to the image\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)  # Add batch dimension\n",
    "            \n",
    "            # Get model prediction\n",
    "            outputs = model(img_tensor)\n",
    "            _, pred = outputs.max(1)\n",
    "            \n",
    "            image_id = int(re.search(r'(\\d+)', file).group())\n",
    "            results.append({\n",
    "                \"ID\": image_id,\n",
    "                \"Filename\": file,\n",
    "                \"Label\": pred.item()\n",
    "            })\n",
    "    return results\n",
    "\n",
    "predictions = generate_predictions(test_dir, test_files, model, device, direct_transform)\n",
    "\n",
    "df = pd.DataFrame(predictions).sort_values(\"ID\")\n",
    "df['ID'] = df['ID'].astype(str) + \".jpg\"\n",
    "df[['ID', 'Label']].to_csv(\"submission_test7.csv\", index=False)\n",
    "print(\"CSV 'submission_test4.csv' generated.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
